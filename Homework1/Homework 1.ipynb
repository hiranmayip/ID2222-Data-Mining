{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 documents the execution times are:\n",
      "Shingling\n",
      "Jaccard similarity between document 3 and 15 is 1.0\n",
      "Jaccard similarity between document 29 and 52 is 1.0\n",
      "Execution time for Shingling is 0.73 seconds\n",
      "MinHashing\n",
      "Jaccard similarity between document 3 and 15 is 1.0\n",
      "Jaccard similarity between document 29 and 52 is 1.0\n",
      "Execution time for MinHashing is 1.023 seconds\n",
      "LSH\n",
      "Execution time for LSH: 0.012 seconds\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "class Shingling():\n",
    "    \n",
    "    shingles = []\n",
    "\n",
    "    def k_shingle(self, text, shingle_size_k: int):\n",
    "        shingles = []\n",
    "        #go through text and add hashed text snippets of shingle size to array\n",
    "        for index in range(len(text)-shingle_size_k+1):\n",
    "            shingle=[text[index+i] for i in range(shingle_size_k)]\n",
    "            shingle = ' '.join(shingle)\n",
    "            shingles.append(hash(shingle))\n",
    "        return list(dict.fromkeys(shingles))\n",
    "    \n",
    "\n",
    "    def __init__(self, text: str, shingle_size_k: int):\n",
    "        self.shingles = self.k_shingle(text, shingle_size_k)\n",
    "\n",
    "\n",
    "class CompareSets():\n",
    "\n",
    "    jaccard_similarity = -1\n",
    "\n",
    "    def compare(self, set1: list, set2: list):\n",
    "        x = set(set1)\n",
    "        y = set(set2)\n",
    "        union = x.union(y)\n",
    "        intersection = x.intersection(y)\n",
    "        return round(len(intersection)/(len(union)), 3)\n",
    "     \n",
    "    def __init__(self, set1: list, set2: list):\n",
    "        self.jaccard_similarity = self.compare(set1, set2)\n",
    "\n",
    "\n",
    "\n",
    "class MinHashing():\n",
    "    \n",
    "    signature = None\n",
    "\n",
    "    \n",
    "    def get_signature(self, a: list, b: list, numHashes, shingleSet):\n",
    "        signature = []\n",
    "        Nextprime = 4294967311\n",
    "        for i in range(0, numHashes):\n",
    "            minHashCode = Nextprime + 1\n",
    "            for shingle in shingleSet:\n",
    "                hash_code = (a[i] * shingle + b[i]) % Nextprime\n",
    "                if hash_code < minHashCode:\n",
    "                    minHashCode = hash_code\n",
    "            signature.append(minHashCode)\n",
    "        return signature\n",
    "\n",
    "\n",
    "    def __init__(self, a: list, b: list, numHashes: int, shingleSet):\n",
    "        self.signature = self.get_signature(a, b,numHashes, shingleSet)\n",
    "\n",
    "\n",
    "class CompareSignatures():\n",
    "    \n",
    "    estimated_similarity = -1\n",
    "\n",
    "    def compare(self, n, set1: list, set2: list):\n",
    "        c = 0\n",
    "        for k in range(0, n):\n",
    "            if set1[k] == set2[k]:\n",
    "                c = c + 1\n",
    "\n",
    "        return c/n\n",
    "\n",
    "    def __init__(self, n: int, set1: list, set2: list):\n",
    "        self.estimated_similarity = self.compare(n,set1, set2)\n",
    "\n",
    "\n",
    "class LSH():\n",
    "   \n",
    "    candidate_pairs = []\n",
    "\n",
    "    def locality_sensitive_hashing(self, sets: list, NumBands: int, NumRows: int, similarity: float):\n",
    "        # NumBands * NumRows = num_hashes\n",
    "        # initialize empty buckets for each band\n",
    "        import collections\n",
    "        num_buckets = 1000\n",
    "        buckets = [[[] for _ in range(num_buckets)] for _ in range(NumBands)]\n",
    "        \n",
    "        for index, signature in enumerate(sets):\n",
    "            for i in range(0, NumBands):\n",
    "                # concatenate and hash into a bucket\n",
    "                chunk = ''.join([str(x) for x in signature[i*NumRows:i*NumRows+NumRows]])\n",
    "                bucket = hash(chunk) % num_buckets\n",
    "                # document #:\n",
    "                buckets[i][bucket].append('Doc #{}'.format(index+1))\n",
    "\n",
    "                \n",
    "        # remove duplicates from the buckets\n",
    "        for i in range(len(buckets)):\n",
    "            for j in range(len(buckets[i])):\n",
    "                buckets[i][j] = list(dict.fromkeys(buckets[i][j]))\n",
    "        # get rid of buckets that don't have two or more elements\n",
    "        for i in range(len(buckets)):\n",
    "            buckets[i] = [i for i in buckets[i] if len(i) > 1]\n",
    "        \n",
    "\n",
    "\n",
    "        from itertools import combinations\n",
    "        candidate_candidate_pairs = []\n",
    "        # construct all of the possible pairs\n",
    "        for band_bucket in buckets:\n",
    "            for bucket in band_bucket:\n",
    "                pairs = [i for i in combinations(bucket, 2)]\n",
    "                candidate_candidate_pairs += pairs\n",
    "        \n",
    "        \n",
    "        # count occurences\n",
    "        c = collections.Counter(candidate_candidate_pairs)\n",
    "        indices = []\n",
    "        for index, value in enumerate(c.values()):\n",
    "            # print(index, value)\n",
    "            if (value/NumBands) >= similarity**NumRows:\n",
    "                indices.append(index)\n",
    "        candidate_pairs = []\n",
    "        for index, pair in enumerate(c.keys()):\n",
    "            if index in indices:\n",
    "                candidate_pairs.append(pair)\n",
    "\n",
    "        return candidate_pairs\n",
    "\n",
    "\n",
    "    def __init__(self, sets: list, NumBands: int, NumRows: int, similarity: float):\n",
    "        self.candidate_pairs = self.locality_sensitive_hashing(sets, NumBands, NumRows, similarity)\n",
    "\n",
    "def get_random_coeff(shingle_size_k):\n",
    "    maxShingleId = 2**32 - 1\n",
    "    randomList = []\n",
    "    while shingle_size_k > 0:\n",
    "        randomIndex = random.randint(0, maxShingleId)\n",
    "        while randomIndex in randomList:\n",
    "            randomIndex = random.randint(0, maxShingleId)\n",
    "        randomList.append(randomIndex)\n",
    "        shingle_size_k = shingle_size_k - 1\n",
    "    return randomList\n",
    "\n",
    "def main():   \n",
    "    \n",
    "    # config\n",
    "    \n",
    "    threshold = 0.8\n",
    "    shingle_size_k = 5\n",
    "    num_docs = 100\n",
    "    print('For {} documents the execution times are:'.format(num_docs))\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    #  Prepare Data  #  \n",
    "    ##################\n",
    "    \n",
    "    data = []\n",
    "  \n",
    "    #extract text from dataset\n",
    "    for file in os.listdir(\"data/\"):\n",
    "        if file.endswith(\".sgm\"):\n",
    "            filename = os.path.join(\"data\", file)\n",
    "            f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "            dataFile = f.read()\n",
    "            soup = BeautifulSoup(dataFile, 'html.parser')\n",
    "            contents = soup.findAll('body')\n",
    "            for content in contents:\n",
    "                data.append(content.text)\n",
    "\n",
    "    #make text lowercase and remove punctuation\n",
    "    for i in data:\n",
    "        i = i.lower()\n",
    "        i = i.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "\n",
    "    \n",
    "     data= list(map(lambda text: re.sub(r'http\\S+', '', text, flags=re.MULTILINE), data))\n",
    "    \n",
    "    def removeHTMLTags(text):\n",
    "        text = re.sub(r'<.*?>', '', text, flags=re.MULTILINE)\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    for i in range(100):\n",
    "        data[i]=data[i].lower()\n",
    "        data[i] = data[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    data= list(map(removeHTMLTags, data))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######################\n",
    "    #  Shingle Documents  #  \n",
    "    #######################\n",
    "\n",
    "    \n",
    "    print('Shingling')\n",
    "    shingled_documents = []\n",
    "    begin = time.time()\n",
    "    for i in range(num_docs):\n",
    "        shingled_documents.append(Shingling(data[i], shingle_size_k))\n",
    "        \n",
    "    for i in range(len(documents)-1):\n",
    "        for j in range(i+1, len(documents)):\n",
    "            similarity = CompareSets(documents[i].shingles, documents[j].shingles).jaccard_similarity\n",
    "            if similarity > threshold:\n",
    "                print('Jaccard similarity between document {} and {} is {}'.format(i, j, similarity))\n",
    "    end = time.time()\n",
    "    print('Execution time for Shingling is {} seconds'.format(round(end-begin , 2)))\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    #  MinHash Shingles and calculate Jaccard Similarity #  \n",
    "    ######################################################\n",
    "    \n",
    "    print('MinHashing')\n",
    "    begin = time.time()\n",
    "    NumHash = 30\n",
    "    a = get_random_coeff(NumHash)           \n",
    "    b = get_random_coeff(NumHash)\n",
    "    \n",
    "    minhash_documents = []\n",
    "    for i in range(num_docs):\n",
    "        minhash_documents.append(MinHashing(a, b,NumHash, documents[i].shingles))\n",
    "    for i in range(len(minhash_documents)-1):\n",
    "        for j in range(i+1, len(minhash_documents)):\n",
    "            similarity = CompareSignatures(NumHash,minhash_documents[i].signature, minhash_documents[j].signature).estimated_similarity\n",
    "            if similarity > threshold:\n",
    "                print('Jaccard similarity between document {} and {} is {}'.format(i, j, similarity))\n",
    "    end = time.time()\n",
    "    print('Execution time for MinHashing is {} seconds'.format(round(end-begin, 3)))\n",
    "    \n",
    "    print('LSH')\n",
    "    begin = time.time()\n",
    "    k=[i.signature for i in minhash_documents]\n",
    "    lsh = LSH(k, 10, 3, 0.8)\n",
    "    end = time.time()\n",
    "    print('Execution time for LSH: {} seconds'.format(round(end-begin, 3)))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
